{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e095994a",
   "metadata": {},
   "source": [
    "# 🧠 Brain Tumor MRI Image Classification\n",
    "Developed using **TensorFlow/Keras** and **PyTorch**\n",
    "\n",
    "This notebook builds and evaluates deep learning models (Custom CNN & Transfer Learning) to classify brain tumors using MRI images. It includes data preprocessing, augmentation, training, evaluation, model comparison, and notes for deployment using Streamlit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f285f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Install & Import Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, MobileNetV2\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "786b2f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreyadas/tf-env/lib/python3.10/site-packages/gdown/parse_url.py:48: UserWarning: You specified a Google Drive link that is not the correct link to download a file. You might want to try `--fuzzy` option or the following url: https://drive.google.com/uc?id=None\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/drive/folders/1KQMtJytnS30zJUqNKbrK0FG6VVdWTFCD?usp=sharing\n",
      "To: /Users/shreyadas/Desktop/404 error/Brain_Tumor_Dataset.zip\n",
      "1.25MB [00:01, 923kB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Brain_Tumor_Dataset.zip'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "# Replace this with your actual sharable Google Drive file link\n",
    "url = 'https://drive.google.com/drive/folders/1KQMtJytnS30zJUqNKbrK0FG6VVdWTFCD?usp=sharing'\n",
    "gdown.download(url, 'Brain_Tumor_Dataset.zip', quiet=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "314d63bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is zip file? False\n"
     ]
    }
   ],
   "source": [
    "print(\"Is zip file?\", zipfile.is_zipfile(zip_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7062e667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1XrJR8wQoh5KtOOSnBhmEmpl4JlqQ3j50\n",
      "From (redirected): https://drive.google.com/uc?id=1XrJR8wQoh5KtOOSnBhmEmpl4JlqQ3j50&confirm=t&uuid=88a2a669-f420-4911-a8d9-271185bdd5e5\n",
      "To: /Users/shreyadas/Desktop/404 error/Brain_Tumor_Dataset.zip\n",
      "100%|██████████| 73.7M/73.7M [00:51<00:00, 1.43MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Brain_Tumor_Dataset.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "# Convert Google Drive share link to direct download link:\n",
    "# FILE ID = 1MQHKl2Q1fKV7Mle3uB2J6KXdZOmy0gB6\n",
    "file_id = \"1XrJR8wQoh5KtOOSnBhmEmpl4JlqQ3j50\"\n",
    "direct_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "# Download using gdown\n",
    "gdown.download(direct_url, 'Brain_Tumor_Dataset.zip', quiet=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7ea01d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted files: ['Tumor', '__MACOSX']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = 'Brain_Tumor_Dataset.zip'\n",
    "extract_path = 'Brain_Tumor_Dataset'\n",
    "\n",
    "# Check if it's a valid zip file before extracting\n",
    "if zipfile.is_zipfile(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "    print(\"Extracted files:\", os.listdir(extract_path))\n",
    "else:\n",
    "    print(\"❌ The file is not a valid ZIP file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7197b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/Users/shreyadas/Downloads/Brain_Tumor_Dataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7cc98bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Found:\", os.path.isdir(dataset_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43cfd5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1955 images belonging to 3 classes.\n",
      "Found 488 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_size = (150, 150)  # Add if not already defined\n",
    "\n",
    "dataset_path = \"/Users/shreyadas/Downloads\"  # <-- Make sure this folder exists\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c281ce82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1955 images belonging to 3 classes.\n",
      "Found 488 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/Users/shreyadas/Downloads\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e458d1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1955 images belonging to 2 classes.\n",
      "Found 488 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/shreyadas/Downloads/Brain_Tumor_Dataset',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/shreyadas/Downloads/Brain_Tumor_Dataset',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5db76891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreyadas/tf-env/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-07-24 19:44:35.126407: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2025-07-24 19:44:35.126592: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-07-24 19:44:35.126609: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-07-24 19:44:35.126805: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-07-24 19:44:35.126825: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">186624</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,888,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m186624\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m23,888,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,908,034</span> (91.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,908,034\u001b[0m (91.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,907,842</span> (91.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,907,842\u001b[0m (91.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🧠 Custom CNN Model (Keras)\n",
    "model_keras = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_keras.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_keras.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0395452b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,850,242</span> (90.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,850,242\u001b[0m (90.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">262,530</span> (1.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m262,530\u001b[0m (1.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🔁 Transfer Learning with ResNet50 (Keras)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "model_resnet = Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_resnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_resnet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81a56854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreyadas/tf-env/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 19:44:44.628584: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9396 - loss: 1.1700"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 282ms/step - accuracy: 0.9404 - loss: 1.1596 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 274ms/step - accuracy: 0.9996 - loss: 0.1473 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 268ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 265ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# 🚂 Train Custom CNN (Keras)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# ✅ Define your custom CNN model\n",
    "model_keras = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_keras.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ✅ Callbacks to avoid overfitting\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=3, restore_best_weights=True),\n",
    "    ModelCheckpoint('cnn_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# ✅ TRAIN the model\n",
    "history = model_keras.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5850c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧠 Custom CNN Model (PyTorch) - To be implemented in a PyTorch training loop\n",
    "# Define transformations, datasets, loaders, model, criterion, optimizer, and training loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6b5e551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Tumor       1.00      1.00      1.00       488\n",
      "    __MACOSX       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00       488\n",
      "   macro avg       0.50      0.50      0.50       488\n",
      "weighted avg       1.00      1.00      1.00       488\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreyadas/tf-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shreyadas/tf-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shreyadas/tf-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shreyadas/tf-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shreyadas/tf-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shreyadas/tf-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shreyadas/tf-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shreyadas/tf-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shreyadas/tf-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/shreyadas/tf-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 📊 Model Evaluation (Keras)\n",
    "val_generator.reset()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(val_generator)):\n",
    "    x, y = val_generator[i]\n",
    "    preds = model_keras.predict(x)\n",
    "    y_true.extend(np.argmax(y, axis=1))\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "labels = list(range(len(val_generator.class_indices)))\n",
    "target_names = list(val_generator.class_indices.keys())\n",
    "\n",
    "print(classification_report(y_true, y_pred, labels=labels, target_names=target_names))\n",
    "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "131ac94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.model_checkpoint.ModelCheckpoint at 0x14db41c00>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelCheckpoint('cnn_model.h5', save_best_only=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7442ba",
   "metadata": {},
   "source": [
    "## 🚀 Streamlit Deployment Notes\n",
    "\n",
    "- Use `cnn_model.h5` or your best model for predictions.\n",
    "- Load model using `load_model()` and predict with image preprocessing.\n",
    "- Include file uploader, prediction label, and confidence score in UI.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
